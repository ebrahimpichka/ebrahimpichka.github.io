<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>First-order methods in Linear Programming: PDHG and GPU-friendly LP solvers | Ebrahim Pichka</title> <meta name="author" content="Ebrahim Pichka"> <meta name="description" content="An introduction to first-order methods for linear programming, focusing on the Primal-Dual Hybrid Gradient (PDHG), the algorithm behind GPU-accelerated LP solvers, and its practical enhancements."> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon_32.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://epichka.com/blog/2026/fom-lp/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "First-order methods in Linear Programming: PDHG and GPU-friendly LP solvers",
      "description": "An introduction to first-order methods for linear programming, focusing on the Primal-Dual Hybrid Gradient (PDHG), the algorithm behind GPU-accelerated LP solvers, and its practical enhancements.",
      "published": "February 15, 2026",
      "authors": [
        {
          "author": "Ebrahim Pichka",
          "authorURL": "",
          "affiliations": [
            {
              "name": "-",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Ebrahim Pichka</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Code</a> </li> <li class="nav-item "> <a class="nav-link" href="/resources/">Resources</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>First-order methods in Linear Programming: PDHG and GPU-friendly LP solvers</h1> <p>An introduction to first-order methods for linear programming, focusing on the Primal-Dual Hybrid Gradient (PDHG), the algorithm behind GPU-accelerated LP solvers, and its practical enhancements.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction-the-gpu-era-in-constrained-optimization">Introduction: The GPU Era in Constrained Optimization</a></div> <div><a href="#building-pdhg-from-scratch-a-walk-through-first-order-methods-for-lp">Building PDHG from Scratch: A Walk Through First-Order Methods for LP</a></div> <div><a href="#pdlp-making-pdhg-production-ready">PDLP: Making PDHG Production-Ready</a></div> <div><a href="#performance-how-fast-is-it-really">Performance: How Fast Is It Really?</a></div> <div><a href="#under-the-hood-theoretical-foundations">Under the Hood: Theoretical Foundations</a></div> <div><a href="#code-example-implementing-basic-pdhg">Code Example: Implementing Basic PDHG</a></div> <div><a href="#practical-considerations">Practical Considerations</a></div> <div><a href="#recommended-resources">Recommended Resources</a></div> <div><a href="#conclusion">Conclusion</a></div> </nav> </d-contents> <p><img src="..\..\..\assets\img\post_content\fom-lp\pdhg_spiral.png" alt="" style="margin:auto; display:block;" class="img-fluid rounded z-depth-1"></p> <h2 id="introduction-the-gpu-era-in-constrained-optimization">Introduction: The GPU Era in Constrained Optimization</h2> <p>If you’ve been following the optimization community lately, you might have noticed something interesting happening: <strong>GPUs are finally coming for linear programming</strong>.</p> <p>For decades, linear programming (LP) solvers have been dominated by two workhorses: the simplex method and interior-point methods (IPMs). These methods are mature, reliable, and backed by decades of theoretical and practical refinement. But they have a challenge: as problems grow to massive scale, their reliance on <strong>matrix factorizations</strong> and <strong>sequential operations</strong> becomes a bottleneck, especially on modern parallel hardware like GPUs.</p> <h3 id="the-new-wave-of-gpu-accelerated-solvers">The New Wave of GPU-Accelerated Solvers</h3> <p>In the past couple of years, we’ve seen an explosion of interest in GPU-accelerated LP solvers:</p> <ul> <li> <p><strong>NVIDIA cuOpt</strong> (2024): NVIDIA released and open-sourced <a href="https://github.com/NVIDIA/cuopt" rel="external nofollow noopener" target="_blank">cuOpt</a>, a GPU-accelerated optimization engine that excels in mixed integer linear programming (MILP), linear programming (LP), and vehicle routing problems (VRP). Their <a href="https://developer.nvidia.com/blog/accelerate-large-linear-programming-problems-with-nvidia-cuopt/" rel="external nofollow noopener" target="_blank">developer blog</a> demonstrates substantial speedups on large-scale problems.</p> </li> <li> <p><strong>Gurobi Integration</strong>: The industry-leading commercial solver Gurobi <a href="https://www.gurobi.com/lp/all/gpu-accelerated-solver/" rel="external nofollow noopener" target="_blank">adopted GPU acceleration</a> based on similar first-order methods, recognizing the potential of this approach.</p> </li> <li> <p><strong>Open-Source Ecosystem</strong>: A vibrant ecosystem of open-source solvers emerged, including <a href="https://github.com/MIT-Lu-Lab/cuPDLPx" rel="external nofollow noopener" target="_blank">cuPDLPx</a> and <a href="https://github.com/jinwen-yang/cuPDLP.jl" rel="external nofollow noopener" target="_blank">cuPDLP.jl</a>, Google’s <a href="https://developers.google.com/optimization/lp/pdlp_math" rel="external nofollow noopener" target="_blank">PDLP</a>, and <a href="https://github.com/MIT-Lu-Lab/MPAX" rel="external nofollow noopener" target="_blank">MPAX</a>.</p> </li> </ul> <p>But here’s the interesting part: all of these solvers are built on <strong>first-order methods</strong> (FOMs), specifically variants of the <strong>Primal-Dual Hybrid Gradient (PDHG)</strong> algorithm. This represents a different philosophy from traditional LP solving, and it’s worth understanding why this approach is gaining traction.</p> <h3 id="why-first-order-methods-why-gpus">Why First-Order Methods? Why GPUs?</h3> <p>The key insight is simple: <strong>GPUs excel at massively parallel operations, particularly matrix-vector multiplications</strong>. Modern GPUs can perform thousands of such operations simultaneously with enormous throughput. Traditional LP methods (simplex and IPMs) rely heavily on solving linear systems via matrix factorizations—operations that are inherently sequential and difficult to parallelize effectively.</p> <p>First-order methods, on the other hand, are built around simple iterative updates involving matrix-vector products: $Ax$, $A^Ty$. No factorizations. No solving linear systems. Just multiply and update. This computational profile aligns beautifully with GPU architectures.</p> <p>The tradeoff? First-order methods typically require more iterations to converge than their second-order counterparts. But when each iteration can be dramatically faster on a GPU, this iteration count penalty often becomes irrelevant—especially for massive problems where factorization costs grow prohibitively.</p> <hr> <h2 id="building-pdhg-from-scratch-a-walk-through-first-order-methods-for-lp">Building PDHG from Scratch: A Walk Through First-Order Methods for LP</h2> <p>Let’s understand how we arrived at PDHG by starting from scratch. We’ll attempt to build a first-order method for LP, see where each approach fails, and understand how PDHG elegantly resolves these challenges.</p> <h3 id="the-linear-programming-problem">The Linear Programming Problem</h3> <p>Consider the standard form LP:</p> \[\begin{align} \min_{x \in \mathbb{R}^n} \quad &amp; c^T x \\ \text{s.t.} \quad &amp; Ax = b \\ &amp; x \geq 0 \end{align}\] <p>where $A \in \mathbb{R}^{m \times n}$, $b \in \mathbb{R}^m$, and $c \in \mathbb{R}^n$. The dual problem is:</p> \[\begin{align} \max_{y \in \mathbb{R}^m} \quad &amp; b^T y \\ \text{s.t.} \quad &amp; A^T y \leq c \end{align}\] <p>Our goal is to find a first-order method that:</p> <ol> <li>Uses only simple operations (especially matrix-vector products)</li> <li>Avoids solving linear systems or factorizations</li> <li>Actually converges to an optimal solution</li> <li>Can leverage parallel hardware like GPUs</li> </ol> <h3 id="attempt-1-projected-gradient-descent-pgd">Attempt 1: Projected Gradient Descent (PGD)</h3> <p><strong>Why start here?</strong> For unconstrained optimization, gradient descent is the canonical first-order method. When we have constraints, the natural extension is <strong>projected gradient descent</strong>: take a gradient step, then project back onto the feasible set.</p> <p>The algorithm would be:</p> \[x^{k+1} = \text{proj}_{\mathcal{C}}(x^k - \eta c)\] <p>where $\mathcal{C} = {x \in \mathbb{R}^n : Ax = b, x \geq 0}$ is our feasible set and $\eta &gt; 0$ is the step-size.</p> <p><strong>What is projection?</strong> The projection of a point $z$ onto a set $\mathcal{C}$ is the closest point in $\mathcal{C}$ to $z$:</p> \[\text{proj}_{\mathcal{C}}(z) = \arg\min_{x \in \mathcal{C}} \|x - z\|^2\] <p>Geometrically, it’s like “snapping” $z$ to the nearest feasible point.</p> <p><strong>How is it computed?</strong> This depends on the set $\mathcal{C}$:</p> <ul> <li>For simple sets like boxes ($l \leq x \leq u$), projection is trivial: just clamp each coordinate</li> <li>For our LP constraints ${x : Ax = b, x \geq 0}$, projection requires solving:</li> </ul> \[\begin{align} \min_{x} \quad &amp; \frac{1}{2}\|x - z\|^2 \\ \text{s.t.} \quad &amp; Ax = b \\ &amp; x \geq 0 \end{align}\] <p>This is itself a <strong>quadratic program</strong> with equality and inequality constraints!</p> <p><strong>The Problem:</strong> Solving this QP requires:</p> <ul> <li>Either forming and solving a linear system $A(A^T)^{-1}$ (if we eliminate the equality constraints)</li> <li>Or using an iterative QP solver</li> </ul> <p>Both options involve solving linear systems or running an optimization algorithm inside our optimization algorithm. For large-scale LP, computing the projection can be as expensive as solving the original problem! This defeats our goal of having a simple, GPU-friendly method.</p> <p><strong>Key Insight:</strong> We need to somehow handle the constraints separately—keeping the “easy” constraints (like $x \geq 0$) and dealing with the “hard” constraints (like $Ax = b$) differently.</p> <h3 id="attempt-2-dualization-and-gradient-descent-ascent-gda">Attempt 2: Dualization and Gradient Descent-Ascent (GDA)</h3> <p><strong>Why move to a primal-dual approach?</strong> The key observation is that our constraints fall into two categories:</p> <ol> <li> <strong>Simple constraints</strong>: $x \geq 0$ (projection is trivial: $\max(x, 0)$ element-wise)</li> <li> <strong>Complex constraints</strong>: $Ax = b$ (projection requires solving a system)</li> </ol> <p>What if we could keep the simple constraints explicit and handle the complex ones differently?</p> <p><strong>The solution:</strong> Use <strong>Lagrangian duality</strong>. Instead of projecting onto $Ax = b$, we dualize this constraint by introducing dual variables $y$ and work with the Lagrangian:</p> \[\mathcal{L}(x, y) = c^T x + y^T(b - Ax)\] <p>Notice that:</p> <ul> <li>If $Ax = b$ (primal feasible), then $y^T(b - Ax) = 0$ and $\mathcal{L}(x,y) = c^T x$</li> <li>If $Ax \neq b$, we can pick $y$ to make $\mathcal{L}(x,y)$ arbitrarily bad</li> </ul> <p>This gives us the <strong>primal-dual formulation</strong>:</p> \[\min_{x \geq 0} \max_{y} \mathcal{L}(x, y) = \min_{x \geq 0} \max_{y} \left[ c^T x - y^T Ax + b^T y \right]\] <p>More compactly, with the indicator function $\iota_{\mathbb{R}^n_+}(x)$ (which is 0 if $x \geq 0$, infinity otherwise):</p> \[\min_{x} \max_{y} L(x, y) := c^T x + \iota_{\mathbb{R}^n_+}(x) - y^T A x + b^T y\] <p><strong>Why is this better?</strong></p> <ul> <li>By convex duality theory, saddle points $(x^<em>, y^</em>)$ of this Lagrangian correspond to optimal primal-dual pairs</li> <li>Now we only need to project onto $x \geq 0$, which is trivial!</li> <li>We’ve traded one hard projection for a saddle point problem</li> </ul> <p><strong>Gradient Descent-Ascent:</strong> For saddle point problems, the natural first-order method is gradient descent in $x$ (minimization) and gradient ascent in $y$ (maximization):</p> \[\begin{align} x^{k+1} &amp;= \text{proj}_{\mathbb{R}^n_+}(x^k - \eta \nabla_x L(x^k, y^k)) \\ &amp;= \text{proj}_{\mathbb{R}^n_+}(x^k - \eta(c - A^T y^k)) \\ &amp;= \max(x^k + \eta A^T y^k - \eta c, 0) \\[1em] y^{k+1} &amp;= y^k + \sigma \nabla_y L(x^k, y^k) \\ &amp;= y^k + \sigma(b - A x^k) \\ &amp;= y^k - \sigma A x^k + \sigma b \end{align}\] <p>where $\eta, \sigma &gt; 0$ are primal and dual step-sizes. The projection is now just a max operation—exactly what we wanted!</p> <p><strong>Does it work?</strong> Let’s test on a simple example.</p> <p>Consider the simple bilinear saddle point problem:</p> \[\min_{x \geq 0} \max_y (x - 3)y\] <p>The unique saddle point is at $(x^<em>, y^</em>) = (3, 0)$. Starting from $(x^0, y^0) = (2, 2)$ with step-sizes $\eta = \sigma = 0.2$, GDA gives:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simple GDA example showing divergence
</span><span class="k">def</span> <span class="nf">gda_update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="n">x_new</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span> <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>      <span class="c1"># gradient of L w.r.t. x is y
</span>    <span class="n">y_new</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>      <span class="c1"># gradient of L w.r.t. y is (x - 3)
</span>    <span class="k">return</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">y_new</span>

<span class="c1"># Run GDA from (2, 2)
</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">gda_update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">10</span> <span class="ow">or</span> <span class="nf">abs</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>  <span class="c1"># Diverging!
</span>        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Diverged at iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">break</span>

<span class="c1"># Output: Diverged at iteration 15
</span></code></pre></div></div> <p>The iterates spiral <strong>outward</strong> rather than converging to $(3, 0)$. Plotting the trajectory shows ever-widening circles.</p> <p><strong>Why does GDA fail?</strong> The problem is that GDA updates each variable based on the gradient at the <em>current</em> point. For saddle point problems, this creates a “chasing” behavior where $x$ and $y$ oscillate and amplify each other’s errors rather than correcting them. Mathematically, the update matrix has eigenvalues outside the unit circle, causing divergence.</p> <p>This is a fundamental limitation: <strong>GDA does not converge for bilinear saddle point problems</strong> (which includes all LPs!). We need something better.</p> <h3 id="attempt-3-proximal-point-method-ppm">Attempt 3: Proximal Point Method (PPM)</h3> <p><strong>Why does GDA fail, and what fixes it?</strong> GDA fails because it uses gradient information from the <em>current</em> iterate, creating instability. What if we could use gradient information from the <em>next</em> iterate instead?</p> <p>This is the idea behind the <strong>Proximal Point Method</strong>. Instead of the explicit update: \(x^{k+1} = x^k - \eta \nabla f(x^k)\)</p> <p>PPM solves an implicit equation: \(x^{k+1} = x^k - \eta \nabla f(x^{k+1})\)</p> <p>For our saddle point problem, this becomes:</p> \[(x^{k+1}, y^{k+1}) = \arg\min_{x \geq 0} \max_y \left[ L(x, y) + \frac{1}{2\eta}\|x - x^k\|^2 - \frac{1}{2\sigma}\|y - y^k\|^2 \right]\] <p>The quadratic penalty terms $\frac{1}{2\eta}|x - x^k|^2$ and $-\frac{1}{2\sigma}|y - y^k|^2$ act as regularizers, preventing the iterates from moving too far in one step.</p> <p><strong>Why this works:</strong> The implicit gradient creates a stabilizing effect. Geometrically, we’re not just following the gradient direction blindly—we’re finding a point that balances between:</p> <ul> <li>Moving in the gradient direction (improving the objective)</li> <li>Staying close to the current iterate (stability)</li> </ul> <p>This regularization fixes GDA’s divergence problem. In fact, on the same toy problem where GDA diverged, PPM would converge smoothly to the saddle point!</p> <p><strong>The catch:</strong> This is an <em>implicit</em> update. To compute $(x^{k+1}, y^{k+1})$, we need to solve the saddle point problem shown above at every iteration. This subproblem is nearly as expensive as our original LP for large-scale problems—completely impractical.</p> <p><strong>The dilemma:</strong></p> <ul> <li>GDA is explicit and cheap per iteration, but <strong>diverges</strong> </li> <li>PPM converges beautifully, but <strong>requires solving a subproblem at each step</strong> </li> </ul> <p>Can we get the best of both worlds?</p> <h3 id="the-solution-primal-dual-hybrid-gradient-pdhg">The Solution: Primal-Dual Hybrid Gradient (PDHG)</h3> <p>Yes! PDHG (also known as the Chambolle-Pock algorithm, after its originators) ingeniously combines explicit computation with convergence guarantees.</p> <p><strong>The key insight:</strong> What if we could approximate the implicit PPM update without actually solving it? PDHG achieves this through an <strong>extrapolation trick</strong>:</p> \[\begin{align} x^{k+1} &amp;\leftarrow \text{proj}_{\mathbb{R}^n_+}(x^k + \eta A^T y^k - \eta c) \quad \text{(primal update, like GDA)} \\ y^{k+1} &amp;\leftarrow y^k - \sigma A(\textcolor{red}{2x^{k+1} - x^k}) + \sigma b \quad \text{(dual update with extrapolation!)} \end{align}\] <p>The primal update is identical to GDA. The magic is in the dual update: instead of using $x^k$ or $x^{k+1}$, we use $\textcolor{red}{2x^{k+1} - x^k}$.</p> <p><strong>What is this extrapolated point?</strong></p> <p>Let’s break down $2x^{k+1} - x^k$: \(2x^{k+1} - x^k = x^{k+1} + \underbrace{(x^{k+1} - x^k)}_{\text{displacement}}\)</p> <p>This is the current iterate <strong>plus</strong> the displacement vector. Geometrically, it’s extrapolating along the direction of movement, predicting where the primal variable is “heading.”</p> <p><strong>Why does the extrapolation work?</strong></p> <p>Think about what we’re trying to fix from GDA. In GDA, the dual update at iteration $k$ uses $x^k$, which is “stale”—by the time we compute $y^{k+1}$, we already have the newer $x^{k+1}$. Using $x^{k+1}$ directly would be better, but still not ideal.</p> <p>The extrapolation $2x^{k+1} - x^k$ goes further: it estimates what $x^{k+2}$ might be. This implicitly approximates the “next iterate” idea from PPM, but without solving the implicit problem!</p> <p><strong>Multiple theoretical perspectives:</strong></p> <ol> <li> <p><strong>Operator theory</strong>: PDHG can be proven equivalent to a preconditioned proximal point method, inheriting PPM’s convergence guarantees</p> </li> <li> <p><strong>Predictor-corrector</strong>: The primal step predicts the next $x$; the extrapolation corrects for this prediction in the dual update</p> </li> <li> <p><strong>Momentum interpretation</strong>: Rewriting as $x^{k+1} + (x^{k+1} - x^k)$ shows it adds momentum to the iterate</p> </li> </ol> <p>Let’s verify this actually works on our toy problem:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pdhg_update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="n">x_new</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span> <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">y_new</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x_new</span> <span class="o">-</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># Extrapolation!
</span>    <span class="k">return</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">y_new</span>

<span class="c1"># Run PDHG from same starting point (2, 2) where GDA diverged
</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">pdhg_update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s">: x = </span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, y = </span><span class="si">{</span><span class="n">y</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Result: Converges to (3.0, 0.0)!
</span></code></pre></div></div> <p><strong>It works!</strong> With PDHG, the iterates spiral <strong>inward</strong> toward the saddle point $(3, 0)$. The extrapolation provides just enough stabilization to ensure convergence, giving us:</p> <ul> <li>Explicit, simple iterations (like GDA)</li> <li>Guaranteed convergence (like PPM)</li> <li>No subproblems to solve (unlike PPM)</li> </ul> <p>This is exactly what we needed!</p> <h3 id="the-computational-advantage">The Computational Advantage</h3> <p>Now we see why PDHG is perfect for GPU-accelerated LP solving. Each PDHG iteration requires only:</p> <ol> <li> <strong>Two matrix-vector products</strong>: $A^T y$ and $A(2x^{k+1} - x^k)$</li> <li> <strong>Element-wise operations</strong>: Additions, subtractions, and max operations for projection</li> </ol> <p>That’s it! No linear system solves. No matrix factorizations. No iterative subsolvers. Everything is:</p> <ul> <li> <strong>Explicit</strong>: Each operation has a closed-form expression</li> <li> <strong>Parallelizable</strong>: Matrix-vector products and element-wise ops parallelize perfectly</li> <li> <strong>Memory-efficient</strong>: Only need to store $x$, $y$, and the matrix $A$</li> </ul> <p>This computational profile is <strong>perfectly suited for GPUs</strong>, which excel at:</p> <ul> <li>Massively parallel matrix-vector multiplications</li> <li>Simple arithmetic operations across large vectors</li> <li>Operations that don’t require sequential dependencies</li> </ul> <p><strong>Summary so far:</strong></p> <ul> <li>PGD: Projection too expensive (requires solving a QP)</li> <li>GDA: Simple and cheap, but diverges</li> <li>PPM: Converges, but requires solving a subproblem</li> <li>PDHG: Explicit, converges, and GPU-friendly!</li> </ul> <h3 id="the-spiral-dynamics-of-pdhg">The Spiral Dynamics of PDHG</h3> <p>One fascinating observed property of PDHG when applied to LP is its distinctive <strong>spiral ray</strong> behavior. When visualizing the trajectory of iterates in primal-dual space, you often see a spiral pattern.</p> <p>Within phases where the active set of variables (which variables are at their bounds) remains constant, the behavior can be understood through a dynamical systems lens. The iterates exhibit two simultaneous behaviors:</p> <ul> <li> <strong>Spiral-in rotation</strong>: The iterates circle toward a central point, improving primal and dual feasibility</li> <li> <strong>Forward movement</strong>: The iterates progress along a ray direction, improving the optimality gap</li> </ul> <p>When the active set changes—when a variable hits its bound or leaves it—the algorithm transitions to a new spiral pattern with a different center and ray direction. This phase-by-phase behavior is characteristic of first-order primal-dual algorithms on LP and differs fundamentally from the edge-following behavior of simplex methods or the central-path-following behavior of interior-point methods.</p> <hr> <h2 id="pdlp-making-pdhg-production-ready">PDLP: Making PDHG Production-Ready</h2> <p>While vanilla PDHG is elegant, it’s not ready for prime time. To build a practical, general-purpose LP solver, we need several enhancements. This is where <strong>PDLP</strong> (Primal-Dual hybrid gradient for Linear Programming) comes in.</p> <h3 id="the-general-lp-form">The General LP Form</h3> <p>PDLP works with a more general LP formulation than the standard form:</p> \[\begin{align} \min_x \quad &amp; c^T x \\ \text{s.t.} \quad &amp; Ax = b \\ &amp; Gx \geq h \\ &amp; l \leq x \leq u \end{align}\] <p>where $G \in \mathbb{R}^{m_1 \times n}$, $A \in \mathbb{R}^{m_2 \times n}$, and $l, u$ can include $-\infty$ and $\infty$ for unbounded variables.</p> <p>This formulation avoids introducing auxiliary variables (which would increase problem size and potentially degrade convergence).</p> <h3 id="the-base-pdhg-algorithm-for-pdlp">The Base PDHG Algorithm for PDLP</h3> <p>PDLP solves the primal-dual formulation:</p> \[\min_{x \in X} \max_{y \in Y} L(x, y) := c^T x - y^T K x + q^T y\] <p>where:</p> <ul> <li>$K^T = [G^T, A^T]$ stacks the constraint matrices</li> <li>$q^T = [h^T, b^T]$ stacks the right-hand sides</li> <li>$X = {x : l \leq x \leq u}$ (simple box constraints)</li> <li>$Y = {y : y_{1:m_1} \geq 0}$ (dual variables for inequalities are non-negative)</li> </ul> <p>The PDHG update becomes:</p> \[\begin{align} x^{k+1} &amp;\leftarrow \text{proj}_X(x^k - \tau(c - K^T y^k)) \\ y^{k+1} &amp;\leftarrow \text{proj}_Y(y^k + \sigma(q - K(2x^{k+1} - x^k))) \end{align}\] <p>The step-sizes are parameterized as $\tau = \eta/\omega$ and $\sigma = \eta\omega$, where:</p> <ul> <li>$\eta$ controls the overall step-size scale</li> <li>$\omega$ (the “primal weight”) balances progress between primal and dual</li> </ul> <p>Both projections $\text{proj}_X$ and $\text{proj}_Y$ are trivial: just clamping to box constraints!</p> <h3 id="critical-enhancements">Critical Enhancements</h3> <p>Vanilla PDHG, while theoretically sound, isn’t immediately competitive with industrial solvers in practice. Empirical studies have shown that the base algorithm solves significantly fewer problem instances to desired accuracy levels compared to enhanced versions.</p> <p>With practical enhancements, modern implementations of PDHG-based solvers (like PDLP and its variants) achieve dramatically better performance—often solving several times more instances to both moderate and high accuracy. Let’s understand what makes the difference.</p> <h4 id="1-preconditioning">1. Preconditioning</h4> <p>First-order methods are notoriously sensitive to problem conditioning—the ratio between the largest and smallest singular values of the constraint matrix. Poorly conditioned problems can converge very slowly.</p> <p><strong>Diagonal preconditioning</strong> rescales the problem to improve conditioning:</p> \[\tilde{K} = D_1 K D_2\] <p>where $D_1$ and $D_2$ are positive diagonal matrices chosen to make $\tilde{K}$ “well-balanced” (having rows and columns with similar norms).</p> <p>Several preconditioning strategies exist:</p> <ul> <li> <strong>Ruiz rescaling</strong>: Iteratively rescales rows and columns to equilibrate their norms</li> <li> <strong>Pock-Chambolle preconditioning</strong>: Theory-driven diagonal rescaling based on the algorithm’s convergence analysis</li> <li> <strong>Hybrid approaches</strong>: Combining multiple preconditioning techniques</li> </ul> <p>This preprocessing step is computationally cheap (involving only row/column norm computations) but can dramatically improve convergence, especially for ill-conditioned problems.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified Ruiz rescaling (pseudocode)
</span><span class="k">def</span> <span class="nf">ruiz_rescaling</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">D1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">K</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">D2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">K</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="n">row_norms</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">K</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">col_norms</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">K</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        
        <span class="n">D1</span> <span class="o">*=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">row_norms</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
        <span class="n">D2</span> <span class="o">*=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">col_norms</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
        
        <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">D1</span><span class="p">)</span> <span class="o">@</span> <span class="n">K</span> <span class="o">@</span> <span class="n">np</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">D2</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">D1</span><span class="p">,</span> <span class="n">D2</span>
</code></pre></div></div> <p>After solving the preconditioned problem, the original solution is recovered by applying the inverse scaling.</p> <h4 id="2-adaptive-restarts">2. Adaptive Restarts</h4> <p>One of the most powerful enhancements is <strong>adaptive restarting</strong>. The core idea: periodically check progress, and when sufficient improvement is detected, restart the algorithm from the current iterate to begin a fresh “epoch.”</p> <p>Why does this help? Many LPs exhibit <strong>two-stage convergence</strong>:</p> <ol> <li> <strong>Sublinear phase</strong>: The algorithm initially identifies the optimal active set (which variables should be at their bounds)</li> <li> <strong>Linear phase</strong>: Once the active set is identified, convergence accelerates dramatically</li> </ol> <p>Restarting exploits this by detecting when we’ve transitioned to the fast linear convergence regime and “resetting” to capitalize on it.</p> <p>The restart condition typically monitors a progress metric—such as the fixed-point residual (how much the iterate moves in one PDHG step). When this metric decays by a sufficient factor (e.g., by a factor of $1/e$), the algorithm restarts:</p> \[\|z^{n,k} - \text{PDHG}(z^{n,k})\|_P \leq \frac{1}{e} \|z^{n,0} - \text{PDHG}(z^{n,0})\|_P\] <p>where $P$ is an appropriate norm for measuring PDHG progress, and $n$ indexes restart epochs.</p> <p>This adaptive scheme doesn’t require knowing problem-dependent constants (like sharpness parameters) that are difficult to estimate in practice. When combined with proper step-size selection, restarting achieves <strong>optimal complexity</strong> for first-order methods:</p> \[O\left(\sqrt{\frac{\|A\|^2}{\alpha}} \log \frac{1}{\epsilon}\right)\] <p>where $\alpha$ represents a problem-dependent sharpness parameter. This complexity matches theoretical lower bounds for first-order methods on LP, making it essentially unimprovable from a worst-case perspective.</p> <h4 id="3-halpern-iteration-and-reflection">3. Halpern Iteration and Reflection</h4> <p>Recent algorithmic variants incorporate <strong>Halpern-type acceleration</strong>, a classical technique from fixed-point theory. The Halpern scheme modifies the basic PDHG iteration by maintaining an “anchor” to the initial solution:</p> \[z^{k+1} = \frac{k+1}{k+2} \text{PDHG}(z^k) + \frac{1}{k+2} z^0\] <p>This weighted average between the PDHG step and the initial point has several advantages:</p> <ul> <li>Eliminates the need to track and update average iterates explicitly</li> <li>Provides similar convergence guarantees to the average-iterate analysis</li> <li>Simplifies the implementation and restart logic</li> <li>Enables stronger theoretical guarantees for certain problem classes</li> </ul> <p><strong>Reflected Halpern PDHG</strong> enhances this further by applying the Halpern iteration to a reflected operator:</p> \[z^{k+1} = \frac{k+1}{k+2} (2\text{PDHG}(z^k) - z^k) + \frac{1}{k+2} z^0\] <p>The reflection $2\text{PDHG}(·) - I$ can be interpreted as taking a more aggressive step, which empirically and theoretically leads to faster convergence. The reflection technique has deep connections to operator theory and has been successfully applied to various optimization algorithms.</p> <h4 id="4-adaptive-primal-weight">4. Adaptive Primal Weight</h4> <p>The primal weight $\omega$ (recall $\tau = \eta/\omega$ and $\sigma = \eta\omega$) balances the progress between primal and dual variables. If $\omega$ is too large, the dual makes slow progress; if too small, the primal lags behind.</p> <p>Modern implementations adaptively adjust $\omega$ to balance primal and dual progress. The heuristic goal is to approximately equalize distances to optimality in both spaces:</p> \[\text{primal distance} \approx \text{dual distance}\] <p>This adjustment typically happens at restart events. To avoid oscillations, the updates use exponential smoothing:</p> \[\omega_{\text{new}} = (1-\theta) \omega_{\text{old}} + \theta \omega_{\text{suggested}}\] <p>where $\theta \in [0,1]$ controls the smoothing rate and $\omega_{\text{suggested}}$ is computed based on observed primal/dual progress.</p> <p>While adaptive primal weight adjustment improves robustness across diverse problem instances, it’s not perfect—per-instance manual tuning can sometimes yield better performance. Determining the ideal primal weight remains an active research direction.</p> <h4 id="5-infeasibility-detection">5. Infeasibility Detection</h4> <p>A practical solver must be able to detect when an LP is infeasible or unbounded. First-order methods naturally produce sequences that can encode infeasibility information.</p> <p>Modern PDLP implementations monitor quantities related to the iterate differences and normalized cumulative iterates. If these quantities converge to non-zero limits with certain properties, they can provide:</p> <ul> <li>Certificates of primal infeasibility (showing no feasible solution exists)</li> <li>Certificates of dual unboundedness (showing the primal is unbounded)</li> <li>Certificates of dual infeasibility (showing the dual is unbounded)</li> </ul> <p>The key insight is that the algorithm’s natural trajectory encodes this information—no special infeasibility detection procedure is needed. Recent algorithmic variants (particularly those using Halpern-type iterations with restarts) have been shown to detect infeasibility with strong theoretical guarantees.</p> <hr> <h2 id="performance-how-fast-is-it-really">Performance: How Fast Is It Really?</h2> <p>The performance gains from GPU acceleration can be substantial, particularly as problem scale increases.</p> <h3 id="gpu-vs-cpu">GPU vs CPU</h3> <p>GPU implementations of PDHG-based solvers show significant advantages over CPU implementations:</p> <p><strong>General trends</strong>:</p> <ul> <li>For moderate accuracy requirements, GPU implementations solve a higher percentage of benchmark instances faster</li> <li>For high accuracy requirements, the GPU advantage becomes even more pronounced</li> <li>The speedup grows with problem scale—GPU implementations excel on large instances</li> </ul> <p>Multi-threaded CPU implementations can partially close the gap, but typically still lag behind GPU performance, especially on large-scale problems. The GPU’s massive parallelism in matrix-vector operations provides a fundamental architectural advantage that’s difficult to overcome with CPU threading alone.</p> <h3 id="gpu-vs-traditional-solvers">GPU vs Traditional Solvers</h3> <p>Comparing GPU-accelerated first-order methods to traditional commercial solvers reveals an interesting performance profile:</p> <ul> <li> <strong>Small problems</strong>: Traditional solvers (using simplex or interior-point methods) are typically faster since factorization overhead remains manageable</li> <li> <strong>Medium problems</strong>: GPU-accelerated FOMs become competitive</li> <li> <strong>Large problems</strong>: GPU-accelerated FOMs can show dramatic speedups, sometimes multiple orders of magnitude</li> </ul> <p>The crossover point typically occurs when:</p> <ul> <li>The constraint matrix has substantial size (tens to hundreds of thousands of nonzeros)</li> <li>The problem structure is amenable to parallel matrix-vector products</li> <li>The LP doesn’t have special structure that traditional methods can exploit</li> </ul> <h3 id="industry-adoption">Industry Adoption</h3> <p>The promising results have driven rapid industry adoption:</p> <ul> <li> <strong>COPT</strong> (Cardinal Optimizer): Integrated GPU-accelerated PDHG variants, showing strong performance on standard benchmarks</li> <li> <strong>NVIDIA</strong>: Developed cuOpt with GPU-accelerated LP solving capabilities, demonstrating competitive performance against traditional CPU solvers</li> <li> <strong>Google</strong>: Made PDLP available in OR-Tools for large-scale applications</li> </ul> <hr> <h2 id="under-the-hood-theoretical-foundations">Under the Hood: Theoretical Foundations</h2> <p>Now that we’ve seen PDHG works in practice, let’s understand <em>why</em> it works. The theory is elegant and provides intuition for the algorithmic choices.</p> <h3 id="progress-metrics">Progress Metrics</h3> <p>To analyze convergence, we need to measure progress. For LP, there are several natural metrics:</p> <p><strong>1. KKT Error</strong>: Measures violation of optimality conditions:</p> \[\text{KKT}(z) = \max\{\|c - A^T y - s\|_\infty, \|Ax - b\|_\infty, \|x^T s\|_\infty, \|x^-\|_\infty, \|s^-\|_\infty\}\] <p>where $x^- = \min(x, 0)$ (negative part) and $s$ are dual slack variables.</p> <p><strong>2. Normalized Duality Gap</strong>: Scale-invariant measure of optimality:</p> \[\rho_r(z) = \frac{c^T x - b^T y}{r + |c^T x| + |b^T y|}\] <p><strong>3. Fixed-Point Residual</strong>: Movement after one PDHG iteration:</p> \[\|z^k - \text{PDHG}(z^k)\|_P\] <p>where $P$ is the natural metric for PDHG.</p> <p>These metrics are related: if any goes to zero, so do the others (with explicit rate conversions).</p> <h3 id="sublinear-convergence">Sublinear Convergence</h3> <p>For vanilla PDHG with step-size $\eta &lt; 1/|A|^2$, we have:</p> <p><strong>Theorem</strong> (Ergodic/Average Iterate): The average iterate $\bar{z}^k = \frac{1}{k}\sum_{i=1}^k z^i$ satisfies:</p> \[\text{KKT}(\bar{z}^k) = O\left(\frac{1}{k}\right)\] <p>This $O(1/k)$ rate is standard for first-order methods on convex problems.</p> <p><strong>Intuition</strong>: The average smooths out oscillations in individual iterates. Think of it as a low-pass filter that removes high-frequency noise while preserving the signal (convergence to optimality).</p> <h3 id="linear-convergence-under-sharpness">Linear Convergence under Sharpness</h3> <p>The game-changer is <strong>linear convergence</strong>. Under a mild condition called “sharpness,” PDHG achieves exponential convergence.</p> <p><strong>Definition</strong> (Sharpness): An LP is $\alpha$-sharp if for all primal-dual pairs $z$ near the optimal set $Z^*$:</p> \[\text{dist}(z, Z^*) \leq \frac{1}{\alpha} \text{KKT}(z)\] <p>Intuitively, sharpness means the KKT error tightly bounds the distance to optimality. It holds for many LPs, including:</p> <ul> <li>LPs with unique optimal solutions</li> <li>Non-degenerate LPs</li> <li>LPs where the optimal face has certain regularity properties</li> </ul> <p><strong>Theorem</strong> (Local Linear Convergence): For an $\alpha$-sharp LP, the last iterate $z^k$ satisfies:</p> \[\text{dist}(z^{k+1}, Z^*) \leq \left(1 - \frac{\alpha^2 \eta^2}{2}\right) \text{dist}(z^k, Z^*)\] <p>With optimal step-size $\eta = \Theta(1/|A|)$, this gives convergence rate:</p> \[O\left(\frac{\|A\|^2}{\alpha^2} \log \frac{1}{\epsilon}\right)\] <p>The $\log(1/\epsilon)$ is exponentially better than $1/ \epsilon$ for vanilla methods!</p> <h3 id="optimal-complexity-via-restarts">Optimal Complexity via Restarts</h3> <p>Restarting achieves the <em>optimal</em> complexity for first-order methods on LP:</p> \[O\left(\sqrt{\frac{\|A\|^2}{\alpha}} \log \frac{1}{\epsilon}\right)\] <p>This matches the complexity lower bound proven for FOMs on LP. The square root improvement over non-restarted PDHG is massive for poorly conditioned problems!</p> <p><strong>Why does restarting help?</strong> It exploits the two-stage behavior:</p> <ol> <li>Initial sublinear phase identifies the optimal face</li> <li>Once identified, the local linear convergence kicks in</li> <li>Restarting “resets” the clock to capitalize on faster local convergence</li> </ol> <hr> <h2 id="code-example-implementing-basic-pdhg">Code Example: Implementing Basic PDHG</h2> <p>Let’s implement a simple version of PDHG to see how straightforward it is:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="kn">from</span> <span class="n">scipy.sparse.linalg</span> <span class="kn">import</span> <span class="n">norm</span> <span class="k">as</span> <span class="n">sparse_norm</span>

<span class="k">class</span> <span class="nc">SimplePDHG</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Simplified PDHG solver for LP in standard form:
        min c</span><span class="sh">'</span><span class="s">x  s.t.  Ax = b, x &gt;= 0
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">eta_factor</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="n">self</span><span class="p">.</span><span class="n">A</span> <span class="o">=</span> <span class="nf">csr_matrix</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>  <span class="c1"># Use sparse matrix
</span>        <span class="n">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">m</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        
        <span class="c1"># Set step-size: eta &lt; 1/||A||
</span>        <span class="n">A_norm</span> <span class="o">=</span> <span class="nf">sparse_norm</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">A</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Spectral norm
</span>        <span class="n">self</span><span class="p">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta_factor</span> <span class="o">/</span> <span class="n">A_norm</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">eta</span>  <span class="c1"># Equal step-sizes
</span>        
    <span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="c1"># Initialize at zero
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">m</span><span class="p">)</span>
        
        <span class="c1"># Track convergence
</span>        <span class="n">gaps</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="c1"># Store old x for extrapolation
</span>            <span class="n">x_old</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
            
            <span class="c1"># Primal update: x^{k+1} = proj_{R+}(x^k + eta*A'y^k - eta*c)
</span>            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">A</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">c</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">maximum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Project to non-negative orthant
</span>            
            <span class="c1"># Dual update with extrapolation: 
</span>            <span class="c1"># y^{k+1} = y^k - sigma*A(2x^{k+1} - x^k) + sigma*b
</span>            <span class="n">x_extrap</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_old</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">A</span> <span class="o">@</span> <span class="n">x_extrap</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">b</span><span class="p">)</span>
            
            <span class="c1"># Compute duality gap every 10 iterations
</span>            <span class="k">if</span> <span class="n">k</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">primal_obj</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">c</span> <span class="o">@</span> <span class="n">x</span>
                <span class="n">dual_obj</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">b</span> <span class="o">@</span> <span class="n">y</span>
                <span class="n">gap</span> <span class="o">=</span> <span class="nf">abs</span><span class="p">(</span><span class="n">primal_obj</span> <span class="o">-</span> <span class="n">dual_obj</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nf">abs</span><span class="p">(</span><span class="n">primal_obj</span><span class="p">))</span>
                <span class="n">gaps</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">gap</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="n">gap</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
                    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Converged in </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s"> iterations</span><span class="sh">"</span><span class="p">)</span>
                    <span class="k">break</span>
        
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gaps</span>

<span class="c1"># Example: Solve a small LP
</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">50</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Generate random LP: min c'x s.t. Ax = b, x &gt;= 0
</span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">x_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>  <span class="c1"># Make feasible
</span><span class="n">b</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">x_true</span>

<span class="n">solver</span> <span class="o">=</span> <span class="nc">SimplePDHG</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">x_sol</span><span class="p">,</span> <span class="n">y_sol</span><span class="p">,</span> <span class="n">gaps</span> <span class="o">=</span> <span class="n">solver</span><span class="p">.</span><span class="nf">solve</span><span class="p">()</span>

<span class="c1"># Plot convergence
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">semilogy</span><span class="p">(</span><span class="n">gaps</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Iteration (x10)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Relative duality gap</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">PDHG Convergence</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p>This implementation is about 50 lines of code! The real production solvers (cuPDLP, PDLP) add:</p> <ul> <li>Sparse matrix optimizations</li> <li>GPU kernels for matrix-vector products</li> <li>All the enhancements we discussed (preconditioning, restarts, adaptive weights, etc.)</li> <li>Infeasibility detection</li> <li>Warm-starting capabilities</li> </ul> <p>But the core algorithm is exactly what we’ve shown.</p> <hr> <h2 id="practical-considerations">Practical Considerations</h2> <h3 id="when-to-use-gpu-accelerated-foms">When to Use GPU-accelerated FOMs</h3> <p><strong>Use GPU-accelerated first-order LP solvers when</strong>:</p> <ul> <li>Working with large-scale problems (hundreds of thousands to millions of variables/constraints)</li> <li>Need to solve many similar LPs repeatedly (warm-starting helps!)</li> <li>Care more about fast time-to-solution than extreme accuracy</li> <li>Have access to GPU hardware</li> <li>Problem structure is amenable to parallel matrix-vector operations</li> </ul> <p><strong>Use traditional solvers (simplex/IPM) when</strong>:</p> <ul> <li>Problem is small to medium scale</li> <li>Need extreme accuracy (10+ significant digits)</li> <li>Need exact vertex solutions (requires crossover procedures)</li> <li>Problem has special structure that traditional methods exploit well</li> <li>Working on CPU-only systems with well-optimized traditional solver implementations</li> </ul> <h3 id="limitations-and-future-directions">Limitations and Future Directions</h3> <p>Current limitations of first-order LP solvers:</p> <ol> <li> <strong>High-accuracy solutions</strong>: Achieving $\epsilon &lt; 10^{-10}$ can be slow</li> <li> <strong>Hyperparameter sensitivity</strong>: Step-size and primal weight tuning matters</li> <li> <strong>Crossover</strong>: Converting to exact vertex solutions needs more work</li> <li> <strong>Problem-specific performance</strong>: Some LPs are harder for FOMs than others (we don’t fully understand why)</li> </ol> <p>Active research directions:</p> <ul> <li>Adaptive step-size selection (rather than constant step-sizes)</li> <li>Better warm-starting strategies</li> <li>Hybrid methods combining FOMs with traditional approaches</li> <li>Extending to mixed-integer programming (branch-and-bound with FOM solves at nodes)</li> </ul> <hr> <h2 id="recommended-resources">Recommended Resources</h2> <p>For deeper understanding, I highly recommend:</p> <p><strong>Books</strong>:</p> <ol> <li> <strong>“First-Order Methods in Optimization”</strong> by Amir Beck - Comprehensive treatment of first-order methods with clear proofs and accessible presentation</li> <li> <strong>“Large-Scale Convex Optimization: Algorithms &amp; Analyses via Monotone Operators”</strong> by Ernest K. Ryu and Wotao Yin - Modern perspective on operator splitting methods including PDHG</li> </ol> <p><strong>Papers</strong>:</p> <ol> <li> <strong>“Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient”</strong> (Applegate et al., 2021) - The original PDLP paper describing the practical solver</li> <li> <strong>“cuPDLP.jl: A GPU Implementation of Restarted PDHG”</strong> (Lu &amp; Yang, 2023) - Details on GPU implementation and performance</li> <li> <strong>“An Overview of GPU-based First-Order Methods for Linear Programming”</strong> (Lu &amp; Yang, 2025) - A comprehensive survey of the field covering theoretical foundations, algorithmic developments, and practical implementations</li> </ol> <p><em>Note: This blog post draws inspiration from the general algorithmic ideas and landscape of first-order methods for LP as surveyed in the literature, particularly the third paper above, while presenting concepts in an accessible manner with original explanations.</em></p> <p><strong>Code</strong>:</p> <ul> <li> <a href="https://github.com/jinwen-yang/cuPDLP.jl" rel="external nofollow noopener" target="_blank">cuPDLP.jl</a> - Julia GPU implementation</li> <li> <a href="https://developers.google.com/optimization/lp/pdlp" rel="external nofollow noopener" target="_blank">Google OR-Tools PDLP</a> - Production C++ implementation</li> <li> <a href="https://github.com/MIT-Lu-Lab/MPAX" rel="external nofollow noopener" target="_blank">MPAX</a> - JAX implementation with latest enhancements</li> </ul> <hr> <h2 id="conclusion">Conclusion</h2> <p>The rise of GPU-accelerated first-order methods for linear programming represents a genuine paradigm shift in large-scale optimization. By embracing the strengths of modern parallel hardware and accepting that more simple iterations can beat fewer complex ones, methods like PDHG and PDLP are solving previously intractable problems at unprecedented speeds.</p> <p>We’ve seen how PDHG emerges naturally from trying to build a practical first-order method for LP saddle point problems, how practical enhancements transform it from a toy algorithm to an industrial-grade solver, and how elegant theory explains its remarkable empirical performance.</p> <p>Just as GPUs revolutionized deep learning by efficiently handling parallel computations, they’re now reshaping optimization. And we’re still in the early days—like interior-point methods in the 1990s, there’s enormous potential for further improvements in both theory and practice.</p> <p>The future of large-scale LP solving is parallel, and it’s already here.</p> <hr> <p><em>Questions? Thoughts? Found this helpful? Let me know! And if you’re working on large-scale LP problems, give cuPDLP or PDLP a try—you might be surprised by the performance.</em></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ebrahimpichka/ebrahimpichka.github.io","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"top","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Ebrahim Pichka. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-JF4RVNMJBY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-JF4RVNMJBY");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>